{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import PIL.Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from torch2trt import torch2trt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-arrival",
   "metadata": {},
   "source": [
    "# Part 1: \n",
    "回帰モデル学習\n",
    "\n",
    "最初は、データセットを読み取るための`XYDataset`クラスを定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(path, width):\n",
    "    \"\"\"Gets the x value from the image filename\"\"\"\n",
    "    return (float(int(path.split(\"_\")[1])) - width/2) / (width/2)\n",
    "\n",
    "def get_y(path, height):\n",
    "    \"\"\"Gets the y value from the image filename\"\"\"\n",
    "    return (float(int(path.split(\"_\")[2])) - height/2) / (height/2)\n",
    "\n",
    "class XYDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.image_paths = glob.glob(os.path.join(self.directory, '*.jpg'))\n",
    "        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "\n",
    "        image = PIL.Image.open(image_path)\n",
    "        width, height = image.size\n",
    "        x = float(get_x(os.path.basename(image_path), width))\n",
    "        y = float(get_y(os.path.basename(image_path), height))\n",
    "\n",
    "        if float(np.random.rand(1)) > 0.5:\n",
    "            image = transforms.functional.hflip(image)\n",
    "            x = -x\n",
    "\n",
    "        image = self.color_jitter(image)\n",
    "        image = transforms.functional.resize(image, (224, 224))\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        image = image.numpy()[::-1].copy()\n",
    "        image = torch.from_numpy(image)\n",
    "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "        return image, torch.tensor([x, y]).float()\n",
    "\n",
    "dataset = XYDataset('dataset/free')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-hometown",
   "metadata": {},
   "source": [
    "そして、学習用と検証用のデータセットを`DataLoader`に渡す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 0.1\n",
    "num_test = int(test_percent * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-syria",
   "metadata": {},
   "source": [
    "これからモデルのお構築に入る。\n",
    "\n",
    "最初に、学習済みの`ResNet18`のモデルをおダウンロードして、最後のレイヤーを２出力の`torch.nn.Linear`を変換する。\n",
    "\n",
    "できたモデルをCUDAデバイス(GPU)に移動する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-defendant",
   "metadata": {},
   "source": [
    "各エポック、学習ループと検証ループを行う。\n",
    "\n",
    "学習ループでは、学習データをモデルを与え、モデルはラベルを予測できるようにチューニングする。\n",
    "\n",
    "検証ループでは、データをモデルに与え、モデル精度を計算する。\n",
    "\n",
    "一番精度が高い（ロスが低い）モデルを、`best_steering_model.pth`として保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "BEST_MODEL_PATH = 'best_steering_model_xy.pth'\n",
    "best_loss = 1e9\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        train_loss += float(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        test_loss += float(loss)\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    display.clear_output(wait = True)\n",
    "    plt.plot(train_losses, label = 'Training Loss')\n",
    "    plt.plot(test_losses, label = 'Test Loss')\n",
    "    plt.legend()\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    print('epoch %d: %f, %f' % (epoch, train_loss, test_loss))\n",
    "    if test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_loss = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-matter",
   "metadata": {},
   "source": [
    "最後に、Pytorch形式のモデルを NVIDIA の TensorRT 形式のモデルに変形する。\n",
    "\n",
    "そのために、`torch2trt`というライブラリーを使う。\n",
    "\n",
    "前のセルでできたモデルを一旦ロードして、変形を行う。\n",
    "\n",
    "最終的のモデルを`best_steering_model_xy_trt.pth`として保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.cuda().eval().half()\n",
    "model.load_state_dict(torch.load('best_steering_model_xy.pth'))\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# prepare empty input\n",
    "data = torch.zeros((1, 3, 224, 224)).cuda().half()\n",
    "\n",
    "# Convert Pytorch model to TensorRT\n",
    "model_trt = torch2trt(model, [data], fp16_mode=True)\n",
    "\n",
    "torch.save(model_trt.state_dict(), 'best_steering_model_xy_trt.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-validation",
   "metadata": {},
   "source": [
    "# Part 2: \n",
    "分類モデル学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-thriller",
   "metadata": {},
   "source": [
    "データセットを `torchvision.datasets` と`torchvision.utils`を使って読み取る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "    'dataset',\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_num = int(0.1*len(dataset))\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - test_num, test_num])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-marijuana",
   "metadata": {},
   "source": [
    "ResNet18 をダウンロードして、最後のレイヤー（fc）だけを入れ替える。\n",
    "\n",
    "最終的に、2クラス（障害物あり、障害物なし）を予測します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-salvation",
   "metadata": {},
   "source": [
    "最後に、`torch.optim.Adam`で ResNet の重みを最適化する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "BEST_MODEL_PATH = 'best_collision_model_resnet18.pth'\n",
    "best_loss = 1e4\n",
    "\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += float(loss)\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    test_loss = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        test_loss += float(loss)\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    display.clear_output(wait= True)\n",
    "    plt.plot(train_losses, label = 'Training Loss')\n",
    "    plt.plot(test_losses, label = 'Test Loss')\n",
    "    plt.legend()\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    print('epoch %d: %f, %f' % (epoch, train_loss, test_loss))\n",
    "    if test_loss <= best_loss:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_loss = test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.cuda().eval().half()\n",
    "model.load_state_dict(torch.load('best_collision_model_resnet18.pth'))\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# prepare empty input\n",
    "data = torch.zeros((1, 3, 224, 224)).cuda().half()\n",
    "\n",
    "# Convert Pytorch model to TensorRT\n",
    "model_trt = torch2trt(model, [data], fp16_mode=True)\n",
    "\n",
    "torch.save(model_trt.state_dict(), 'best_collision_model_resnet18_trt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-student",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
